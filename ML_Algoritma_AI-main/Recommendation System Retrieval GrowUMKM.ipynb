{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow-recommenders\n","!pip install mysql-connector-python"],"metadata":{"id":"R64gDSv3LO2M"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zboHa_iDKGmT"},"outputs":[],"source":["import os\n","import json\n","from typing import Dict, Text\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_recommenders as tfrs\n","import mysql.connector\n","import tempfile"]},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"BLbWT9G7KxSZ"}},{"cell_type":"code","source":["def get_mysql_credentials():\n","    with open(\"config2.json\") as config_file: # Please upload the config2.json file to root folder\n","        config = json.load(config_file)\n","        return config.get(\"mysql\", {})\n","\n","def connect_to_database():\n","    credentials = get_mysql_credentials()\n","\n","    cnx = mysql.connector.connect(\n","        user=credentials.get(\"user\"),\n","        password=credentials.get(\"password\"),\n","        host=credentials.get(\"host\"),\n","        database=credentials.get(\"database\"),\n","    )\n","    return cnx"],"metadata":{"id":"zA1viy5gKrkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnx = connect_to_database()\n","cursor = cnx.cursor()\n","\n","query_tbl_userview = \"SELECT DISTINCT id_user, id_umkm from tbl_userview\"\n","cursor.execute(query_tbl_userview)\n","\n","col_userview = [\"id_user\", \"id_umkm\"]\n","\n","user = pd.DataFrame(cursor.fetchall(), columns=col_userview)\n","\n","umkm = user[\"id_umkm\"].unique()\n","umkm = pd.DataFrame({\"id_umkm\": umkm})"],"metadata":{"id":"a0xbWpXBLzlF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparing Data"],"metadata":{"id":"qTH162v0N_Xf"}},{"cell_type":"code","source":["# Convert relevant object columns to strings in the UMKM dataset\n","user[\"id_user\"] = user[\"id_user\"].astype(str)\n","user[\"id_umkm\"] = user[\"id_umkm\"].astype(str)\n","umkm[\"id_umkm\"] = umkm[\"id_umkm\"].astype(str)\n","\n","# Convert pandas DataFrames to TensorFlow tensors\n","def map_function(row):\n","    return {\"id_user\": row[\"id_user\"], \"id_umkm\": row[\"id_umkm\"]}\n","\n","ratings = tf.data.Dataset.from_tensor_slices(dict(user))\n","ratings = ratings.map(map_function)\n","\n","umkm = tf.data.Dataset.from_tensor_slices(umkm[\"id_umkm\"])\n","\n","ratings = ratings.map(\n","    lambda x: {\n","        \"id_umkm\": x[\"id_umkm\"],\n","        \"id_user\": x[\"id_user\"],\n","    }\n",")\n","umkm = umkm.map(lambda x: x)"],"metadata":{"id":"a5LqdnGkL904"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocessing Data"],"metadata":{"id":"4hKJvC0_OLnC"}},{"cell_type":"code","source":["# Shuffle the dataset\n","shuffled = ratings.shuffle(buffer_size=len(ratings), seed=42)\n","\n","# Take first 4000 elements for train\n","train = shuffled.take(4000)\n","\n","# Skip 4000 elements and take next 320 for test\n","test = shuffled.skip(4000).take(320)\n","\n","ID_umkm = umkm.batch(100)\n","ID_user = ratings.batch(1000).map(lambda x: x[\"id_user\"])\n","\n","unique_ID_umkm = np.unique(np.concatenate(list(ID_umkm)))\n","unique_ID_user = np.unique(np.concatenate(list(ID_user)))"],"metadata":{"id":"MCKVKtI1OH-_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build Model"],"metadata":{"id":"xP1CGpMHOSPo"}},{"cell_type":"code","source":["embedding_dimension = 32\n","\n","user_model = tf.keras.Sequential(\n","    [\n","        tf.keras.layers.StringLookup(vocabulary=unique_ID_user, mask_token=None),\n","        # We add an additional embedding to account for unknown tokens.\n","        tf.keras.layers.Embedding(len(unique_ID_user) + 1, embedding_dimension),\n","    ]\n",")\n","\n","umkm_model = tf.keras.Sequential(\n","    [\n","        tf.keras.layers.StringLookup(vocabulary=unique_ID_umkm, mask_token=None),\n","        tf.keras.layers.Embedding(len(unique_ID_umkm) + 1, embedding_dimension),\n","    ]\n",")\n","\n","metrics = tfrs.metrics.FactorizedTopK(candidates=umkm.batch(128).map(umkm_model))\n","task = tfrs.tasks.Retrieval(metrics=metrics)"],"metadata":{"id":"Axk1zE3EOTKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UmkmlensModel(tfrs.Model):\n","    def __init__(self, user_model, umkm_model):\n","        super().__init__()\n","        self.umkm_model: tf.keras.Model = umkm_model\n","        self.user_model: tf.keras.Model = user_model\n","        self.task: tf.keras.layers.Layer = task\n","\n","    def compute_loss(\n","        self, features: Dict[Text, tf.Tensor], training=False\n","    ) -> tf.Tensor:\n","        # We pick out the user features and pass them into the user model.\n","        user_embeddings = self.user_model(features[\"id_user\"])\n","        # And pick out the umkm features and pass them into the umkm model,\n","        # getting embeddings back.\n","        positive_umkm_embeddings = self.umkm_model(features[\"id_umkm\"])\n","\n","        # The task computes the loss and the metrics.\n","        return self.task(user_embeddings, positive_umkm_embeddings)"],"metadata":{"id":"VwI5XtT2OWcI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NoBaseClassUmkmlensModel(tf.keras.Model):\n","    def __init__(self, user_model, umkm_model):\n","        super().__init__()\n","        self.umkm_model: tf.keras.Model = umkm_model\n","        self.user_model: tf.keras.Model = user_model\n","        self.task: tf.keras.layers.Layer = task\n","\n","    def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n","        # Set up a gradient tape to record gradients.\n","        with tf.GradientTape() as tape:\n","            # Loss computation.\n","            user_embeddings = self.user_model(features[\"id_user\"])\n","            positive_umkm_embeddings = self.umkm_model(features[\"id_umkm\"])\n","            loss = self.task(user_embeddings, positive_umkm_embeddings)\n","\n","            # Handle regularization losses as well.\n","            regularization_loss = sum(self.losses)\n","\n","            total_loss = loss + regularization_loss\n","\n","        gradients = tape.gradient(total_loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","\n","        metrics = {metric.name: metric.result() for metric in self.metrics}\n","        metrics[\"loss\"] = loss\n","        metrics[\"regularization_loss\"] = regularization_loss\n","        metrics[\"total_loss\"] = total_loss\n","\n","        return metrics\n","\n","    def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n","      # Loss computation.\n","      user_embeddings = self.user_model(features[\"id_user\"])\n","      positive_umkm_embeddings = self.umkm_model(features[\"id_umkm\"])\n","      loss = self.task(user_embeddings, positive_umkm_embeddings)\n","\n","      # Handle regularization losses as well.\n","      regularization_loss = sum(self.losses)\n","\n","      total_loss = loss + regularization_loss\n","\n","      metrics = {metric.name: metric.result() for metric in self.metrics}\n","      metrics[\"loss\"] = loss\n","      metrics[\"regularization_loss\"] = regularization_loss\n","      metrics[\"total_loss\"] = total_loss\n","\n","      return metrics"],"metadata":{"id":"jh4SuG_HOYYZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = UmkmlensModel(user_model, umkm_model)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n","\n","cached_train = train.shuffle(1000).batch(100).cache()\n","cached_test = test.batch(100).cache()"],"metadata":{"id":"x4a4qR5gObKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(cached_train, epochs=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tWdaAm4OnLT","executionInfo":{"status":"ok","timestamp":1703126875736,"user_tz":-420,"elapsed":13071,"user":{"displayName":"Yosi Ronadi M013BSY0076","userId":"05368628543680874988"}},"outputId":"64919f23-95b4-4343-c480-a65f9561c685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","40/40 [==============================] - 4s 95ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0555 - factorized_top_k/top_5_categorical_accuracy: 0.4160 - factorized_top_k/top_10_categorical_accuracy: 0.7972 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 228.7048 - regularization_loss: 0.0000e+00 - total_loss: 228.7048\n","Epoch 2/3\n","40/40 [==============================] - 3s 63ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0555 - factorized_top_k/top_5_categorical_accuracy: 0.4162 - factorized_top_k/top_10_categorical_accuracy: 0.7970 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 228.6791 - regularization_loss: 0.0000e+00 - total_loss: 228.6791\n","Epoch 3/3\n","40/40 [==============================] - 3s 68ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0555 - factorized_top_k/top_5_categorical_accuracy: 0.4162 - factorized_top_k/top_10_categorical_accuracy: 0.7968 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 228.6539 - regularization_loss: 0.0000e+00 - total_loss: 228.6539\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x789fcff50be0>"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"jtVsL23vPM5R"}},{"cell_type":"code","source":["model.evaluate(cached_test, return_dict=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlX4EH2QOpXi","executionInfo":{"status":"ok","timestamp":1703126876514,"user_tz":-420,"elapsed":799,"user":{"displayName":"Yosi Ronadi M013BSY0076","userId":"05368628543680874988"}},"outputId":"f0ee57bb-ebdc-4832-b93b-f8ba356a6e20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 61ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0656 - factorized_top_k/top_5_categorical_accuracy: 0.4938 - factorized_top_k/top_10_categorical_accuracy: 0.8313 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 172.8571 - regularization_loss: 0.0000e+00 - total_loss: 172.8571\n"]},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_1_categorical_accuracy': 0.06562499701976776,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.4937500059604645,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.831250011920929,\n"," 'factorized_top_k/top_50_categorical_accuracy': 1.0,\n"," 'factorized_top_k/top_100_categorical_accuracy': 1.0,\n"," 'loss': 17.88996124267578,\n"," 'regularization_loss': 0,\n"," 'total_loss': 17.88996124267578}"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Create a model that takes in raw query features, and\n","index_model = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n","# recommends movies out of the entire movies dataset.\n","index_model.index_from_dataset(\n","    tf.data.Dataset.zip((umkm.batch(100), umkm.batch(100).map(model.umkm_model)))\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_R2buFGrPJrH","executionInfo":{"status":"ok","timestamp":1703126299350,"user_tz":-420,"elapsed":549,"user":{"displayName":"Yosi Ronadi M013BSY0076","userId":"05368628543680874988"}},"outputId":"bb248a9d-8241-43c4-bcb8-b1cc60878b13"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x789fcc0e3280>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Prediction Test"],"metadata":{"id":"F9QfXWc5PSUJ"}},{"cell_type":"code","source":["# Get recommendations.\n","_, ID_umkm = index_model(tf.constant([\"44\"]))\n","print(f\"Recommendations for user 44: {ID_umkm[0, :5]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40TVMOCKPUcA","executionInfo":{"status":"ok","timestamp":1703126323728,"user_tz":-420,"elapsed":586,"user":{"displayName":"Yosi Ronadi M013BSY0076","userId":"05368628543680874988"}},"outputId":"53deffc0-fbf3-47d0-d88f-f1e4301c8e0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recommendations for user 44: [b'134' b'54' b'132' b'2' b'137']\n"]}]},{"cell_type":"markdown","source":["# Save Model"],"metadata":{"id":"35UNVRZ1PYWp"}},{"cell_type":"code","source":["# Get the current working directory\n","current_directory = os.getcwd()\n","\n","# Specify the directory you want to join\n","specific_directory = \"model\"\n","\n","# Use os.path.join to create the complete path\n","full_path = os.path.join(current_directory, specific_directory)\n","print(full_path)\n","\n","with tempfile.TemporaryDirectory() as tmp:\n","    path = os.path.join(tmp, full_path)\n","\n","    # Save the index.\n","    tf.saved_model.save(index_model, path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fh9ieNJwPZjw","executionInfo":{"status":"ok","timestamp":1703126362827,"user_tz":-420,"elapsed":1232,"user":{"displayName":"Yosi Ronadi M013BSY0076","userId":"05368628543680874988"}},"outputId":"6352ca5f-9f57-45f0-aec0-5b258ae0f3bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/model\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]}]}]}